{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 数据集链接\n",
    "\n",
    "https://www.kaggle.com/competitions/rsna-breast-cancer-detection\n",
    "\n",
    "https://www.kaggle.com/datasets/remekkinas/rsnamodules\n",
    "\n",
    "https://www.kaggle.com/code/vslaykovsky/rsna-2022-whl"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "本笔记本演示了如何将本次比赛的300GB以上的巨大数据集处理成TFRecords，以便在训练期间快速加载数据。\n",
    "\n",
    "TFRecords的优点是可以加载包含许多样本的大量数据，而不是单独加载每个图像和标签。\n",
    "\n",
    "所有图像都调整为1024x1024并保存在100个TFRecords中，使每个TFRecord包含大约550张图像。\n",
    "\n",
    "[RSNA EfficientNetV2 Training Tensorflow TPU](https://www.kaggle.com/code/markwijkhuizen/rsna-efficientnetv2-training-tensorflow-tpu)\n",
    "\n",
    "**V2**\n",
    "\n",
    "* 640x512 -> 1024x1024 resolution\n",
    "* Cropping images\n",
    "* Single image approach, not both CC and MLO image\n",
    "\n",
    "**V3**\n",
    "\n",
    "* 1024x1024 -> 768x1344 based on cropped image ratio\n",
    "* using PNG encoded images instead of raw tensors to reduce disk space needed\n",
    "\n",
    "**V5**\n",
    "\n",
    "此版本中的更新：\n",
    "\n",
    "* 纠正图像的线性/S 形归一化，非常感谢(https://www.kaggle.com/bobdegraaf) (https://www.kaggle.com/code/bobdegraaf/dicomsdl-voi-lut)\n",
    "* 从PNG切换到JPEG，压缩级别为95，以保持在20GB磁盘空间内\n",
    "* 调整裁剪算法，从最大值到阈值搜索，而不是从边缘到阈值搜索\n",
    "* 将裁剪偏移量填充到图像尺寸以保留图像信息，而不是零填充"
   ],
   "metadata": {}
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 安装并可用必要的DICOM处理库"
  },
  {
   "cell_type": "code",
   "source": "%%capture\n# Source: https://www.kaggle.com/code/remekkinas/fast-dicom-processing-1-6-2x-faster?scriptVersionId=113360473\n!pip install /kaggle/input/rsnamodules/dicomsdl-0.109.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl \n\ntry:\n    import pylibjpeg\nexcept:\n   !pip install /kaggle/input/rsna-2022-whl/{pylibjpeg-1.4.0-py3-none-any.whl,python_gdcm-3.0.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl}",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-25T10:59:26.925789Z",
     "iopub.execute_input": "2023-01-25T10:59:26.926223Z",
     "iopub.status.idle": "2023-01-25T10:59:47.847997Z",
     "shell.execute_reply.started": "2023-01-25T10:59:26.926119Z",
     "shell.execute_reply": "2023-01-25T10:59:47.846522Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylibjpeg\n",
    "import pydicom\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.notebook import tqdm\n",
    "from multiprocessing import cpu_count\n",
    "import cv2\n",
    "import glob\n",
    "import importlib\n",
    "import os\n",
    "import joblib\n",
    "import sys\n",
    "import dicomsdl\n",
    "print(f'Tensorflow Version: {tf.__version__}')\n",
    "print(f'Python Version: {sys.version}')\n",
    "\n",
    "# Tensorflow and CV2 set number of threads to 1 for speedup in parallell function mapping\n",
    "tf.config.threading.set_inter_op_parallelism_threads(num_threads=1)\n",
    "cv2.setNumThreads(1)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-25T10:59:47.849939Z",
     "iopub.execute_input": "2023-01-25T10:59:47.850325Z",
     "iopub.status.idle": "2023-01-25T10:59:54.62554Z",
     "shell.execute_reply.started": "2023-01-25T10:59:47.850292Z",
     "shell.execute_reply": "2023-01-25T10:59:54.624383Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Config",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "mpl.rcParams['xtick.labelsize'] = 16\n",
    "mpl.rcParams['ytick.labelsize'] = 16\n",
    "mpl.rcParams['axes.labelsize'] = 18\n",
    "mpl.rcParams['axes.titlesize'] = 24\n",
    "\n",
    "# 用于调试目的的交互标志\n",
    "IS_INTERACTIVE = os.environ['KAGGLE_KERNEL_RUN_TYPE'] == 'Interactive'\n",
    "\n",
    "# 处理图像的尺寸\n",
    "TARGET_HEIGHT = 1344  # 目标高度\n",
    "TARGET_WIDTH = 768    # 目标宽度\n",
    "N_CHANNELS = 1       # 通道数（单通道灰度图像）\n",
    "TARGET_HEIGHT_WIDTH_RATIO = TARGET_HEIGHT / TARGET_WIDTH  # 高宽比\n",
    "\n",
    "# 图像归一化工具，未改善LB得分\n",
    "# 教程见：https://docs.opencv.org/4.x/d5/daf/tutorial_py_histogram_equalization.html\n",
    "CLAHE = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(32, 32))  # 创建CLAHE对象\n",
    "APPLY_CLAHE = False  # 是否应用CLAHE\n",
    "APPLY_EQ_HIST = False  # 是否应用直方图均衡化\n",
    "\n",
    "# 图像格式和配置\n",
    "IMAGE_FORMAT = 'JPG'  # 图像格式为JPG\n",
    "IMAGE_QUALITY = 95     # 图像质量设为95\n",
    "\n",
    "# 随机生成器种子\n",
    "SEED = 42"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-25T10:59:54.626864Z",
     "iopub.execute_input": "2023-01-25T10:59:54.627555Z",
     "iopub.status.idle": "2023-01-25T10:59:54.639937Z",
     "shell.execute_reply.started": "2023-01-25T10:59:54.627522Z",
     "shell.execute_reply": "2023-01-25T10:59:54.637759Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Train",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# 读取RSNA乳腺癌检测的数据集，并为每个图像生成文件路径\n",
    "if IS_INTERACTIVE:\n",
    "    train = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv').head(1024)\n",
    "else:\n",
    "    train = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv')\n",
    "    \n",
    "def get_file_path(args):\n",
    "    patient_id, image_id = args\n",
    "    return f'/kaggle/input/rsna-breast-cancer-detection/train_images/{patient_id}/{image_id}.dcm'\n",
    "    \n",
    "train['file_path'] = train[['patient_id', 'image_id']].apply(get_file_path, axis=1)\n",
    "    \n",
    "display(train.info())\n",
    "display(train.head())"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-25T10:59:54.655291Z",
     "iopub.execute_input": "2023-01-25T10:59:54.655632Z",
     "iopub.status.idle": "2023-01-25T10:59:54.99674Z",
     "shell.execute_reply.started": "2023-01-25T10:59:54.655601Z",
     "shell.execute_reply": "2023-01-25T10:59:54.995536Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# VOI_LUT",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# 来源：https://www.kaggle.com/code/bobdegraaf/dicomsdl-voi-lut\n",
    "def voi_lut(image, dicom):\n",
    "    # 只加载我们需要的变量\n",
    "    center = dicom['WindowCenter']  # 窗口中心\n",
    "    width = dicom['WindowWidth']    # 窗口宽度\n",
    "    bits_stored = dicom['BitsStored']  # 存储位数\n",
    "    voi_lut_function = dicom['VOILUTFunction']  # VOI LUT函数\n",
    "\n",
    "    # 对于SIGMOID函数，center和width是列表，否则是单个值\n",
    "    if isinstance(center, list):\n",
    "        center = center[0]  # 取列表中的第一个值\n",
    "    if isinstance(width, list):\n",
    "        width = width[0]    # 取列表中的第一个值\n",
    "\n",
    "    # 设置y_min, y_max和范围\n",
    "    y_min = 0\n",
    "    y_max = float(2**bits_stored - 1)  # 最大值\n",
    "    y_range = y_max  # 范围\n",
    "\n",
    "    # 默认使用线性函数（所以对于NaN会使用线性）\n",
    "    if voi_lut_function == 'SIGMOID':\n",
    "        # 使用SIGMOID函数进行处理\n",
    "        image = y_range / (1 + np.exp(-4 * (image - center) / width)) + y_min\n",
    "    else:\n",
    "        # 检查宽度是否小于1（在我们的情况下不必要，始终>= 750）\n",
    "        center -= 0.5\n",
    "        width -= 1\n",
    "\n",
    "        # 根据阈值分类图像\n",
    "        below = image <= (center - width / 2)  # 小于下阈值\n",
    "        above = image > (center + width / 2)   # 大于上阈值\n",
    "        between = np.logical_and(~below, ~above)  # 在阈值之间\n",
    "\n",
    "        # 根据分类设置图像值\n",
    "        image[below] = y_min  # 设置小于下阈值的像素为y_min\n",
    "        image[above] = y_max  # 设置大于上阈值的像素为y_max\n",
    "        if between.any():\n",
    "            image[between] = (\n",
    "                ((image[between] - center) / width + 0.5) * y_range + y_min\n",
    "            )  # 在阈值之间的像素进行线性变换\n",
    "\n",
    "    # 归一化，使背景为0，某些图像中0是最大强度\n",
    "    if dicom['PhotometricInterpretation'] == 'MONOCHROME1':\n",
    "        image = np.max(image) - image  # 反转图像\n",
    "\n",
    "    return image  # 返回处理后的图像"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-25T10:59:54.998197Z",
     "iopub.execute_input": "2023-01-25T10:59:54.999008Z",
     "iopub.status.idle": "2023-01-25T10:59:55.008762Z",
     "shell.execute_reply.started": "2023-01-25T10:59:54.998973Z",
     "shell.execute_reply": "2023-01-25T10:59:55.007534Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Crop Image",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# 平滑向量，用于平滑轴的和/标准差\n",
    "def smooth(l):\n",
    "    # 内核大小为向量的1%\n",
    "    kernel_size = int(len(l) * 0.01)\n",
    "    kernel = np.ones(kernel_size) / kernel_size  # 创建平滑内核\n",
    "    return np.convolve(l, kernel, mode='same')  # 使用卷积平滑数据\n",
    "\n",
    "# 根据第一列的和低于最大列和*标准差的5%来计算X偏移\n",
    "def get_x_offset(image, max_col_sum_ratio_threshold=0.05, debug=None):\n",
    "    # 图像维度\n",
    "    H, W = image.shape\n",
    "    # 添加到偏移的百分比边距\n",
    "    margin = int(image.shape[1] * 0.00)\n",
    "    # 根据平滑的和*标准差来捕捉变化的强度列\n",
    "    vv = smooth(image.sum(axis=0).squeeze()) * smooth(image.std(axis=0).squeeze())\n",
    "    # 在前75%的列中找到最大和\n",
    "    vv_argmax = vv[:int(image.shape[1] * 0.75)].argmax()\n",
    "    # 阈值\n",
    "    vv_threshold = vv.max() * max_col_sum_ratio_threshold\n",
    "    \n",
    "    # 找到最大列之后第一个低于阈值的列\n",
    "    for offset, v in enumerate(vv):\n",
    "        # 从vv_argmax开始搜索\n",
    "        if offset < vv_argmax:\n",
    "            continue\n",
    "        \n",
    "        # 找到低于阈值的列\n",
    "        if v < vv_threshold:\n",
    "            offset = min(W, offset + margin)  # 添加边距\n",
    "            break\n",
    "            \n",
    "    # 如果debug参数是ndarray，则进行可视化\n",
    "    if isinstance(debug, np.ndarray):\n",
    "        debug[1].imshow(image)\n",
    "        debug[1].set_title('X 偏移')\n",
    "        vv_scale = H / vv.max() * 0.90\n",
    "        # 绘制值\n",
    "        debug[1].plot(H - vv * vv_scale, c='red', label='vv')\n",
    "        # 阈值线\n",
    "        debug[1].hlines(H - vv_threshold * vv_scale, 0, W - 1, colors='orange', label='阈值')\n",
    "        # 最大值\n",
    "        debug[1].scatter(vv_argmax, H - vv[vv_argmax] * vv_scale, c='blue', s=100, label='最大值', zorder=np.PINF)\n",
    "        # 第一个低于阈值的列\n",
    "        debug[1].scatter(offset, H - vv[offset] * vv_scale, c='purple', s=100, label='偏移', zorder=np.PINF)\n",
    "        debug[1].set_ylim(H, 0)\n",
    "        debug[1].legend()\n",
    "        debug[1].axis('off')\n",
    "        \n",
    "    return offset\n",
    "\n",
    "# 根据第一行的底部和顶部行和低于最大行和*标准差的10%来计算Y偏移\n",
    "def get_y_offsets(image, max_row_sum_ratio_threshold=0.05, debug=None):\n",
    "    # 图像维度\n",
    "    H, W = image.shape\n",
    "    # 添加到偏移的边距\n",
    "    margin = 0\n",
    "    # 根据平滑的和*标准差来捕捉变化的强度行\n",
    "    vv = smooth(image.sum(axis=1).squeeze()) * smooth(image.std(axis=1).squeeze())\n",
    "    # 在四分位行中找到最大和*标准差行\n",
    "    vv_argmax = int(image.shape[0] * 0.25) + vv[int(image.shape[0] * 0.25):int(image.shape[0] * 0.75)].argmax()\n",
    "    # 阈值\n",
    "    vv_threshold = vv.max() * max_row_sum_ratio_threshold\n",
    "    # 默认裁剪偏移\n",
    "    offset_bottom = 0\n",
    "    offset_top = H\n",
    "\n",
    "    # 底部偏移，从argmax到底部搜索\n",
    "    for offset in reversed(range(0, vv_argmax)):\n",
    "        v = vv[offset]\n",
    "        if v < vv_threshold:\n",
    "            offset_bottom = offset  # 找到底部偏移\n",
    "            break\n",
    "    \n",
    "    if isinstance(debug, np.ndarray):\n",
    "        debug[2].imshow(image)\n",
    "        debug[2].set_title('Y 底部偏移')\n",
    "        vv_scale = W / vv.max() * 0.90\n",
    "        # 绘制值\n",
    "        debug[2].plot(vv * vv_scale, np.arange(H), c='red', label='vv')\n",
    "        # 阈值线\n",
    "        debug[2].vlines(vv_threshold * vv_scale, 0, H - 1, colors='orange', label='阈值')\n",
    "        # 最大值\n",
    "        debug[2].scatter(vv[vv_argmax] * vv_scale, vv_argmax, c='blue', s=100, label='最大值', zorder=np.PINF)\n",
    "        # 第一个低于阈值的行\n",
    "        debug[2].scatter(vv[offset_bottom] * vv_scale, offset_bottom, c='purple', s=100, label='偏移', zorder=np.PINF)\n",
    "        debug[2].set_ylim(H, 0)\n",
    "        debug[2].legend()\n",
    "        debug[2].axis('off')\n",
    "            \n",
    "    # 顶部偏移，从argmax到顶部搜索\n",
    "    for offset in range(vv_argmax, H):\n",
    "        v = vv[offset]\n",
    "        if v < vv_threshold:\n",
    "            offset_top = offset  # 找到顶部偏移\n",
    "            break\n",
    "            \n",
    "    if isinstance(debug, np.ndarray):\n",
    "        debug[3].imshow(image)\n",
    "        debug[3].set_title('Y 顶部偏移')\n",
    "        vv_scale = W / vv.max() * 0.90\n",
    "        # 绘制值\n",
    "        debug[3].plot(vv * vv_scale, np.arange(H), c='red', label='vv')\n",
    "        # 阈值线\n",
    "        debug[3].vlines(vv_threshold * vv_scale, 0, H - 1, colors='orange', label='阈值')\n",
    "        # 最大值\n",
    "        debug[3].scatter(vv[vv_argmax] * vv_scale, vv_argmax, c='blue', s=100, label='最大值', zorder=np.PINF)\n",
    "        # 第一个低于阈值的行\n",
    "        debug[3].scatter(vv[offset_top] * vv_scale, offset_top, c='purple', s=100, label='偏移', zorder=np.PINF)\n",
    "        debug[2].set_ylim(H, 0)\n",
    "        debug[3].legend()\n",
    "        debug[3].axis('off')\n",
    "            \n",
    "    return max(0, offset_bottom - margin), min(image.shape[0], offset_top + margin)\n",
    "\n",
    "# 裁剪图像并填充偏移，以目标图像的高宽比保存信息\n",
    "def crop(image, size=None, debug=False):\n",
    "    # 图像维度\n",
    "    H, W = image.shape\n",
    "    # 计算x/底部/顶部偏移\n",
    "    x_offset = get_x_offset(image, debug=debug)\n",
    "    offset_bottom, offset_top = get_y_offsets(image[:, :x_offset], debug=debug)\n",
    "    # 裁剪高度和宽度\n",
    "    h_crop = offset_top - offset_bottom\n",
    "    w_crop = x_offset\n",
    "    \n",
    "    # 将裁剪偏移填充到目标纵横比\n",
    "    if size is not None:\n",
    "        # 高度过大，填充x偏移\n",
    "        if (h_crop / w_crop) > TARGET_HEIGHT_WIDTH_RATIO:\n",
    "            x_offset += int(h_crop / TARGET_HEIGHT_WIDTH_RATIO - w_crop)\n",
    "        else:\n",
    "            # 高度过小，填充底部/顶部偏移\n",
    "            offset_bottom -= int(0.50 * (w_crop * TARGET_HEIGHT_WIDTH_RATIO - h_crop))\n",
    "            offset_bottom_correction = max(0, -offset_bottom)\n",
    "            offset_bottom += offset_bottom_correction\n",
    "\n",
    "            offset_top += int(0.50 * (w_crop * TARGET_HEIGHT_WIDTH_RATIO - h_crop))\n",
    "            offset_top += offset_bottom_correction\n",
    "        \n",
    "    # 裁剪图像\n",
    "    image = image[offset_bottom:offset_top, :x_offset]\n",
    "        \n",
    "    return image  # 返回裁剪后的图像"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-25T11:10:46.337297Z",
     "iopub.execute_input": "2023-01-25T11:10:46.337693Z",
     "iopub.status.idle": "2023-01-25T11:10:46.366616Z",
     "shell.execute_reply.started": "2023-01-25T11:10:46.337659Z",
     "shell.execute_reply": "2023-01-25T11:10:46.365286Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Utility",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# 基于：https://www.kaggle.com/code/remekkinas/fast-dicom-processing-1-6-2x-faster?scriptVersionId=113360473\n",
    "def process(file_path, size=None, dicom_process=True, ret_target=False, crop_image=False, apply_clahe=APPLY_CLAHE, apply_eq_hist=APPLY_EQ_HIST, debug=False):\n",
    "    # 读取DICOM文件\n",
    "    dicom = dicomsdl.open(file_path)\n",
    "    image = dicom.pixelData()  # 获取像素数据\n",
    "    \n",
    "    # 如果开启debug模式，保存原始图像以供调试\n",
    "    if debug:\n",
    "        fig, axes = plt.subplots(1, 5, figsize=(20, 10))\n",
    "        image0 = np.copy(image)  # 复制原始图像\n",
    "        axes[0].imshow(image0)\n",
    "        axes[0].set_title('原始图像')\n",
    "        axes[0].axis('off')\n",
    "    else:\n",
    "        axes = False\n",
    "        \n",
    "    # 进行VOI LUT处理\n",
    "    image = voi_lut(image, dicom)\n",
    "\n",
    "    # 归一化到[0,1]范围\n",
    "    image = (image - image.min()) / (image.max() - image.min())\n",
    "\n",
    "    # 转换为uint8格式，范围[0, 255]\n",
    "    image = (image * 255).astype(np.uint8)\n",
    "    \n",
    "    # 根据左右方向规范化图像，翻转右侧朝向的图像\n",
    "    h0, w0 = image.shape\n",
    "    if image[:, int(-w0 * 0.10):].sum() > image[:, :int(w0 * 0.10)].sum():\n",
    "        image = np.flip(image, axis=1)\n",
    "    \n",
    "    # 如果需要裁剪图像\n",
    "    if crop_image:\n",
    "        image = crop(image, size=size, debug=axes)\n",
    "    \n",
    "    # 调整图像大小\n",
    "    if size is not None:\n",
    "        # 填充黑色像素以获得正确的图像比例\n",
    "        h, w = image.shape\n",
    "        if (h / w) > TARGET_HEIGHT_WIDTH_RATIO:\n",
    "            pad = int(h / TARGET_HEIGHT_WIDTH_RATIO - w)\n",
    "            image = np.pad(image, [[0, 0], [0, pad]])  # 填充右侧\n",
    "            h, w = image.shape\n",
    "        else:\n",
    "            pad = int(0.50 * (w * TARGET_HEIGHT_WIDTH_RATIO - h))\n",
    "            image = np.pad(image, [[pad, pad], [0, 0]])  # 填充上下\n",
    "            h, w = image.shape\n",
    "        # 调整大小\n",
    "        image = cv2.resize(image, size, interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "    # 应用CLAHE对比度增强\n",
    "    # 参考文档：https://docs.opencv.org/4.x/d5/daf/tutorial_py_histogram_equalization.html\n",
    "    if apply_clahe:\n",
    "        image = CLAHE.apply(image)\n",
    "        \n",
    "    # 应用直方图均衡化\n",
    "    # 参考文档：https://docs.opencv.org/4.x/d5/daf/tutorial_py_histogram_equalization.html\n",
    "    if apply_eq_hist:\n",
    "        image = cv2.equalizeHist(image)\n",
    "        \n",
    "    # 如果开启debug模式，显示处理后的图像\n",
    "    if debug:\n",
    "        axes[4].imshow(image)\n",
    "        axes[4].set_title('处理后的图像')\n",
    "        axes[4].axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    # 返回癌症目标\n",
    "    if ret_target:\n",
    "        patient_id = int(file_path.split('/')[-2])  # 提取患者ID\n",
    "        image_id = int(file_path.split('/')[-1].split('.')[0])  # 提取图像ID\n",
    "\n",
    "        target = PATIENT_ID_IMAGE_ID2CANCER[(patient_id, image_id)]  # 获取癌症目标\n",
    "        \n",
    "        return image, target  # 返回图像和目标\n",
    "    # 仅返回图像\n",
    "    else:\n",
    "        if debug:\n",
    "            return image0, image  # 返回原始图像和处理后的图像\n",
    "        else:\n",
    "            return image  # 返回处理后的图像"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-25T11:10:46.965083Z",
     "iopub.execute_input": "2023-01-25T11:10:46.965473Z",
     "iopub.status.idle": "2023-01-25T11:10:46.98285Z",
     "shell.execute_reply.started": "2023-01-25T11:10:46.965442Z",
     "shell.execute_reply": "2023-01-25T11:10:46.981254Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Example Processing",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# 根据交互模式设置N的值\n",
    "N = 4 if IS_INTERACTIVE else 10  \n",
    "# 遍历训练集中前N个文件路径\n",
    "for fp in tqdm(train['file_path'].head(N)):\n",
    "    process(\n",
    "            fp,  # 处理每个文件路径\n",
    "            crop_image=True,  # 开启裁剪图像\n",
    "            size=(TARGET_WIDTH, TARGET_HEIGHT),  # 设置目标大小\n",
    "            debug=True,  # 开启调试模式\n",
    "        )"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-25T11:10:48.441978Z",
     "iopub.execute_input": "2023-01-25T11:10:48.442409Z",
     "iopub.status.idle": "2023-01-25T11:11:09.165967Z",
     "shell.execute_reply.started": "2023-01-25T11:10:48.442373Z",
     "shell.execute_reply": "2023-01-25T11:11:09.163212Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Example Processed Images",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def plot_original_processed_examples(rows=48, cols=5):\n    fig, axes = plt.subplots(rows, cols, figsize=(cols * 4, 6 * rows))\n    for r in tqdm(range(rows)):\n        for c in range(cols):\n            idx = (r * cols) + c\n            image = process(\n                    train.loc[idx, 'file_path'],\n                    crop_image=True,\n                    size=(TARGET_WIDTH, TARGET_HEIGHT),\n                    apply_clahe=APPLY_CLAHE,\n                    apply_eq_hist=APPLY_EQ_HIST,\n                    debug=False,\n                )\n            axes[r, c].imshow(image)\n            axes[r, c].set_title(f'{idx} | processed')\n\n    plt.show()\n    \nplot_original_processed_examples(rows=8 if IS_INTERACTIVE else 32)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-25T11:00:16.332372Z",
     "iopub.execute_input": "2023-01-25T11:00:16.333153Z",
     "iopub.status.idle": "2023-01-25T11:00:59.425002Z",
     "shell.execute_reply.started": "2023-01-25T11:00:16.333114Z",
     "shell.execute_reply": "2023-01-25T11:00:59.423393Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Train",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# 检查所有患者是否同时具有CC和MLO视图\n",
    "if not IS_INTERACTIVE:\n",
    "    # 遍历按患者ID分组的训练集\n",
    "    for g_idx, g in tqdm(train.groupby('patient_id')):\n",
    "        # 如果当前组中不包含CC或MLO视图\n",
    "        if 'CC' not in g['view'].values or 'MLO' not in g['view'].values:\n",
    "            display(g)  # 显示缺少视图的患者数据"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-25T11:00:59.426694Z",
     "iopub.execute_input": "2023-01-25T11:00:59.427256Z",
     "iopub.status.idle": "2023-01-25T11:00:59.435771Z",
     "shell.execute_reply.started": "2023-01-25T11:00:59.427194Z",
     "shell.execute_reply": "2023-01-25T11:00:59.434621Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 将患者ID和图像ID映射到癌症目标\n",
    "PATIENT_ID_IMAGE_ID2CANCER = train.set_index(['patient_id', 'image_id'])['cancer'].to_dict()  "
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-25T11:00:59.437297Z",
     "iopub.execute_input": "2023-01-25T11:00:59.437641Z",
     "iopub.status.idle": "2023-01-25T11:00:59.459773Z",
     "shell.execute_reply.started": "2023-01-25T11:00:59.437609Z",
     "shell.execute_reply": "2023-01-25T11:00:59.457658Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Test",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "test = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/test.csv')\n",
    "display(test.info())\n",
    "display(test.head())"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-25T11:00:59.461449Z",
     "iopub.execute_input": "2023-01-25T11:00:59.461869Z",
     "iopub.status.idle": "2023-01-25T11:00:59.496877Z",
     "shell.execute_reply.started": "2023-01-25T11:00:59.461831Z",
     "shell.execute_reply": "2023-01-25T11:00:59.49536Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Sample Submission",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "sample_submission = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/sample_submission.csv')\n",
    "display(sample_submission.info())\n",
    "display(sample_submission.head())"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-25T11:00:59.498164Z",
     "iopub.execute_input": "2023-01-25T11:00:59.498523Z",
     "iopub.status.idle": "2023-01-25T11:00:59.525714Z",
     "shell.execute_reply.started": "2023-01-25T11:00:59.498492Z",
     "shell.execute_reply": "2023-01-25T11:00:59.524352Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Train Meta Data",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Train data is imbalanced, we have ~50x more negative samples than positive samples\nplt.figure(figsize=(8, 8))\ntrain['cancer'].value_counts().plot(kind='pie', autopct='%1.1f%%', title='Cancer Distribution')\nplt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-25T11:00:59.527304Z",
     "iopub.execute_input": "2023-01-25T11:00:59.527646Z",
     "iopub.status.idle": "2023-01-25T11:00:59.653921Z",
     "shell.execute_reply.started": "2023-01-25T11:00:59.527607Z",
     "shell.execute_reply": "2023-01-25T11:00:59.652583Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Image Statistics",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Patient folder paths\nFOLDER_PATHS = glob.glob('/kaggle/input/rsna-breast-cancer-detection/train_images/*')\nprint(f'Found {len(FOLDER_PATHS)} Train Folders')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-25T11:00:59.655489Z",
     "iopub.execute_input": "2023-01-25T11:00:59.657371Z",
     "iopub.status.idle": "2023-01-25T11:00:59.903763Z",
     "shell.execute_reply.started": "2023-01-25T11:00:59.657332Z",
     "shell.execute_reply": "2023-01-25T11:00:59.902744Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# File paths\nFILE_PATHS = glob.glob('/kaggle/input/rsna-breast-cancer-detection/train_images/*/*.dcm')\nprint(f'Found {len(FILE_PATHS)} Train Files')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-25T11:00:59.904926Z",
     "iopub.execute_input": "2023-01-25T11:00:59.90638Z",
     "iopub.status.idle": "2023-01-25T11:01:55.208963Z",
     "shell.execute_reply.started": "2023-01-25T11:00:59.906333Z",
     "shell.execute_reply": "2023-01-25T11:01:55.206864Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "plt.figure(figsize=(15,8))\nplt.title('Number of Scans Per Patient per Laterality (Left/Right side)')\ntrain.groupby(['patient_id', 'laterality']).apply(len).value_counts().sort_index().plot(kind='bar')\nplt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-25T11:01:55.210787Z",
     "iopub.execute_input": "2023-01-25T11:01:55.211155Z",
     "iopub.status.idle": "2023-01-25T11:01:55.416733Z",
     "shell.execute_reply.started": "2023-01-25T11:01:55.211125Z",
     "shell.execute_reply": "2023-01-25T11:01:55.415927Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# View Counts: AT/LM/ML/LMO are rare, too few samples to train on\ndisplay(train['view'].value_counts().to_frame('count'))",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-25T11:01:55.417733Z",
     "iopub.execute_input": "2023-01-25T11:01:55.418197Z",
     "iopub.status.idle": "2023-01-25T11:01:55.431105Z",
     "shell.execute_reply.started": "2023-01-25T11:01:55.418151Z",
     "shell.execute_reply": "2023-01-25T11:01:55.429639Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Scan View Counts: most patient only have a CC and MLO scan\ndisplay(train.sort_values('view').groupby(['patient_id', 'laterality'])['view'].apply(tuple).value_counts().to_frame('Count'))",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-25T11:01:55.432439Z",
     "iopub.execute_input": "2023-01-25T11:01:55.432774Z",
     "iopub.status.idle": "2023-01-25T11:01:55.465299Z",
     "shell.execute_reply.started": "2023-01-25T11:01:55.432743Z",
     "shell.execute_reply": "2023-01-25T11:01:55.463858Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Image Dimensions",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "np.random.seed(42)\n\n# Get height/width statistics\nN = int(16 if IS_INTERACTIVE else 1024)\nWIDTHS = []\nHEIGHTS = []\nfor fp in tqdm(np.random.choice(FILE_PATHS, N)):\n    h, w = process(fp).shape\n    HEIGHTS.append(h)\n    WIDTHS.append(w)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-25T11:01:55.467447Z",
     "iopub.execute_input": "2023-01-25T11:01:55.467905Z",
     "iopub.status.idle": "2023-01-25T11:02:06.907947Z",
     "shell.execute_reply.started": "2023-01-25T11:01:55.467861Z",
     "shell.execute_reply": "2023-01-25T11:02:06.906604Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Patches are insanely huge!\nplt.figure(figsize=(15,8))\nplt.title('Image Dimensions', size=24)\npd.Series(HEIGHTS).plot(kind='hist', alpha=0.50, label='heights')\npd.Series(WIDTHS).plot(kind='hist', alpha=0.50, label='widths')\nplt.grid()\nplt.legend()\nplt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-25T11:02:06.90947Z",
     "iopub.execute_input": "2023-01-25T11:02:06.909866Z",
     "iopub.status.idle": "2023-01-25T11:02:07.185688Z",
     "shell.execute_reply.started": "2023-01-25T11:02:06.909829Z",
     "shell.execute_reply": "2023-01-25T11:02:07.184166Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Height to Width Ratio's, height is roughly 1.25x width, that's why resize to (512*1.25)x512 = 640x512\ndisplay(pd.Series(np.array(HEIGHTS) / np.array(WIDTHS)).describe().to_frame('Height/Width Ratio\\'s'))\n\nplt.figure(figsize=(15,8))\npd.Series(np.array(HEIGHTS) / np.array(WIDTHS)).plot(kind='hist')\nplt.grid()\nplt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-25T11:02:07.187536Z",
     "iopub.execute_input": "2023-01-25T11:02:07.187903Z",
     "iopub.status.idle": "2023-01-25T11:02:07.40402Z",
     "shell.execute_reply.started": "2023-01-25T11:02:07.187875Z",
     "shell.execute_reply": "2023-01-25T11:02:07.402836Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Cropped Image Dimensions",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "np.random.seed(SEED)\n\nN = int(16 if IS_INTERACTIVE else 1024)\nWIDTHS_CROPPED = []\nHEIGHTS_CROPPED = []\n\nfor fp in tqdm(np.random.choice(FILE_PATHS, N)):\n    h, w = process(fp, crop_image=True).shape\n    WIDTHS_CROPPED.append(h)\n    HEIGHTS_CROPPED.append(w)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-25T11:02:07.405568Z",
     "iopub.execute_input": "2023-01-25T11:02:07.406229Z",
     "iopub.status.idle": "2023-01-25T11:02:19.361987Z",
     "shell.execute_reply.started": "2023-01-25T11:02:07.406185Z",
     "shell.execute_reply": "2023-01-25T11:02:19.360804Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "plt.figure(figsize=(15,8))\nplt.title('Cropped Image Dimensions', size=24)\npd.Series(WIDTHS_CROPPED).plot(kind='hist', alpha=0.50, label='cropped heights')\npd.Series(HEIGHTS_CROPPED).plot(kind='hist', alpha=0.50, label='cropped widths')\nplt.grid()\nplt.legend()\nplt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-25T11:02:19.363438Z",
     "iopub.execute_input": "2023-01-25T11:02:19.364043Z",
     "iopub.status.idle": "2023-01-25T11:02:19.619276Z",
     "shell.execute_reply.started": "2023-01-25T11:02:19.364009Z",
     "shell.execute_reply": "2023-01-25T11:02:19.618548Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Height to Width Ratio's\ndisplay(pd.Series(np.array(WIDTHS_CROPPED) / np.array(HEIGHTS_CROPPED)).describe().to_frame('Cropped Height/Width Ratio\\'s'))\nplt.figure(figsize=(15,8))\npd.Series(np.array(WIDTHS_CROPPED) / np.array(HEIGHTS_CROPPED)).plot(kind='hist')\nplt.grid()\nplt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-25T11:02:19.620525Z",
     "iopub.execute_input": "2023-01-25T11:02:19.620999Z",
     "iopub.status.idle": "2023-01-25T11:02:19.856721Z",
     "shell.execute_reply.started": "2023-01-25T11:02:19.62097Z",
     "shell.execute_reply": "2023-01-25T11:02:19.85589Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Chunk Generation",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Make Pairs of Views as input to the model\nFILE_PATHS_PAIRS = []\nfor row_idx, row in tqdm(train.iterrows(), total=len(train)):\n        FILE_PATHS_PAIRS.append(row[['patient_id', 'image_id']].values)\n        \nFILE_PATHS_PAIRS = np.array(FILE_PATHS_PAIRS, dtype=object)\nprint(f'FILE_PATHS_PAIRS shape: {FILE_PATHS_PAIRS.shape}')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-25T11:02:19.857778Z",
     "iopub.execute_input": "2023-01-25T11:02:19.858216Z",
     "iopub.status.idle": "2023-01-25T11:02:20.288243Z",
     "shell.execute_reply.started": "2023-01-25T11:02:19.858158Z",
     "shell.execute_reply": "2023-01-25T11:02:20.287233Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Put every image in a seperate TFRecord file\nN_CHUNKS = 100\nCHUNKS = np.array_split(FILE_PATHS_PAIRS, N_CHUNKS)\n\nprint(f'N_CHUNKS: {N_CHUNKS}, CHUNK len: {len(CHUNKS[0])}, shape: {CHUNKS[0].shape}')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-25T11:02:20.292558Z",
     "iopub.execute_input": "2023-01-25T11:02:20.292884Z",
     "iopub.status.idle": "2023-01-25T11:02:20.299859Z",
     "shell.execute_reply.started": "2023-01-25T11:02:20.292856Z",
     "shell.execute_reply": "2023-01-25T11:02:20.298341Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Single sample processing\ndef process_chunk(args):\n    patient_id, image_id = args\n    # Define file path\n    fp = f'/kaggle/input/rsna-breast-cancer-detection/train_images/{patient_id}/{image_id}.dcm'\n    # Get processed image and target\n    image, target = process(fp, size=(TARGET_WIDTH, TARGET_HEIGHT), ret_target=True, crop_image=True)\n\n    # Make grayscale channel\n    image = np.expand_dims(image, 2)\n    \n    # Encode PNG\n    if IMAGE_FORMAT == 'PNG':\n        image_serialized = tf.io.encode_png(image, compression=9).numpy()\n    # Encode JPEG\n    else:\n        image_serialized = tf.io.encode_jpeg(image, quality=IMAGE_QUALITY, optimize_size=True).numpy()\n    \n    return image_serialized, target, patient_id, image_id",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-25T11:02:20.302574Z",
     "iopub.execute_input": "2023-01-25T11:02:20.302975Z",
     "iopub.status.idle": "2023-01-25T11:02:20.313005Z",
     "shell.execute_reply.started": "2023-01-25T11:02:20.302939Z",
     "shell.execute_reply": "2023-01-25T11:02:20.312092Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def to_tf_records(chunks):\n    for chunk_idx, chunk in enumerate(tqdm(chunks)):\n        print(f'===== GENERATING TFRECORDS {chunk_idx} =====')\n        tfrecord_name = f'batch_{chunk_idx}.tfrecords'\n        \n        # Create the actual TFRecords\n        options = tf.io.TFRecordOptions(compression_type='GZIP', compression_level=9)\n        with tf.io.TFRecordWriter(tfrecord_name, options=options) as file_writer:\n            # Process Samples in Chunk in Parallell\n            jobs = [joblib.delayed(process_chunk)(args) for args in chunk]\n            chunk_processed = joblib.Parallel(\n                n_jobs=cpu_count(),\n                verbose=0,\n                backend='multiprocessing',\n                prefer='threads',\n            )(jobs)\n            \n            # Add Processed Samples to TFRecord\n            for image, target, patient_id, image_id in chunk_processed:\n                record_bytes = tf.train.Example(features=tf.train.Features(feature={\n                    # Image\n                    'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image])),\n\n                    # target\n                    'target': tf.train.Feature(int64_list=tf.train.Int64List(value=[target])),\n                    \n                    # patient_id\n                    'patient_id': tf.train.Feature(int64_list=tf.train.Int64List(value=[patient_id])),\n                    \n                    # image_id\n                    'image_id': tf.train.Feature(int64_list=tf.train.Int64List(value=[image_id])),\n                })).SerializeToString()\n                file_writer.write(record_bytes)\n            \n# Create TFRecords\nif IS_INTERACTIVE:\n    to_tf_records(CHUNKS[:10])\nelse:\n    to_tf_records(CHUNKS)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-25T11:02:20.314161Z",
     "iopub.execute_input": "2023-01-25T11:02:20.314503Z",
     "iopub.status.idle": "2023-01-25T11:03:00.649071Z",
     "shell.execute_reply.started": "2023-01-25T11:02:20.314475Z",
     "shell.execute_reply": "2023-01-25T11:03:00.647816Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Check TFRecords",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "N = 16 if IS_INTERACTIVE else 32",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-25T11:03:00.650714Z",
     "iopub.execute_input": "2023-01-25T11:03:00.650957Z",
     "iopub.status.idle": "2023-01-25T11:03:00.656144Z",
     "shell.execute_reply.started": "2023-01-25T11:03:00.650934Z",
     "shell.execute_reply": "2023-01-25T11:03:00.655076Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Function to decode the TFRecords\ndef decode_tfrecord(record_bytes):\n    features = tf.io.parse_single_example(record_bytes, {\n        'image': tf.io.FixedLenFeature([], tf.string),\n        'target': tf.io.FixedLenFeature([], tf.int64),\n        'patient_id': tf.io.FixedLenFeature([], tf.int64),\n        'image_id': tf.io.FixedLenFeature([], tf.int64),\n    })\n        \n    if IMAGE_FORMAT == 'PNG':\n        image = tf.io.decode_png(features['image'], channels=N_CHANNELS)\n    else:\n        image = tf.io.decode_jpeg(features['image'], channels=N_CHANNELS)\n        \n    image = tf.reshape(image, [TARGET_HEIGHT, TARGET_WIDTH, N_CHANNELS])\n\n    target = features['target']\n    patient_id = features['patient_id']\n    image_id = features['image_id']\n    \n    return image, target, patient_id, image_id",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-25T11:13:01.713418Z",
     "iopub.execute_input": "2023-01-25T11:13:01.713845Z",
     "iopub.status.idle": "2023-01-25T11:13:01.723494Z",
     "shell.execute_reply.started": "2023-01-25T11:13:01.713811Z",
     "shell.execute_reply": "2023-01-25T11:13:01.721964Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "More on Tensorflow TFRecord Datasets: [TFRecordDataset](https://www.tensorflow.org/api_docs/python/tf/data/TFRecordDataset)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Sample TFRecord Dataset\ndef get_train_dataset():\n    # Read all TFRecord file paths\n    FNAMES_TRAIN_TFRECORDS = tf.io.gfile.glob('./*.tfrecords')\n    # initialize TFRecord dataset\n    train_dataset = tf.data.TFRecordDataset(FNAMES_TRAIN_TFRECORDS, num_parallel_reads=1, compression_type='GZIP')\n    # Decode samples by mapping with decode function\n    train_dataset = train_dataset.map(decode_tfrecord)\n    # Batch samples\n    train_dataset = train_dataset.batch(N)\n    \n    return train_dataset",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-25T11:13:02.171694Z",
     "iopub.execute_input": "2023-01-25T11:13:02.172522Z",
     "iopub.status.idle": "2023-01-25T11:13:02.177962Z",
     "shell.execute_reply.started": "2023-01-25T11:13:02.172488Z",
     "shell.execute_reply": "2023-01-25T11:13:02.177067Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Shows a batch of images\ndef show_batch(dataset, rows=N, cols=1):\n    images, targets, patient_ids, image_ids = next(iter(dataset))\n    images = np.moveaxis(images, 3, 1)\n    fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(cols*6, rows*10))\n    for r in range(rows):\n        for c in range(cols):\n            img = images[r,c]\n            axes[r].imshow(img)\n            if c == 0:\n                target = targets[r]\n                patient_id = patient_ids[r]\n                image_id = image_ids[r]\n                axes[r].set_title(f'target: {target}, patient_id: {patient_id}, image_id: {image_id}', fontsize=12, pad=16)\n        \n    plt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-25T11:13:02.64269Z",
     "iopub.execute_input": "2023-01-25T11:13:02.643057Z",
     "iopub.status.idle": "2023-01-25T11:13:02.651154Z",
     "shell.execute_reply.started": "2023-01-25T11:13:02.643021Z",
     "shell.execute_reply": "2023-01-25T11:13:02.649851Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Show Example Batch\ntrain_dataset = get_train_dataset()\nshow_batch(train_dataset)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-25T11:13:03.136878Z",
     "iopub.execute_input": "2023-01-25T11:13:03.137384Z",
     "iopub.status.idle": "2023-01-25T11:13:04.943075Z",
     "shell.execute_reply.started": "2023-01-25T11:13:03.137344Z",
     "shell.execute_reply": "2023-01-25T11:13:04.942252Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
